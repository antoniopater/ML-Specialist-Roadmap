# ML-Specialist-Roadmap
### My 2â€“3 year public learning & building plan to become a machine learning / deep learning specialist. Transparent progress, real projects, papers, and MLOps.
---
## TL;DR


### - ğŸ“Œ Current focus: Machine Learning Specialization - Andrew Ng
### - ğŸ§ª Active project:
### - ğŸ¯ Quarter goal: Finish all moduls from first course
### - ğŸ—“ï¸ This week: I modul in Regression and Classification


---
### Table of Contents
1. Vision & Rules of the game
2. Curriculum & Progress (courses + milestones)
3. Projects (productionâ€‘grade)
4. Research Practice (paper log & replications)
5. Skills Matrix (tech & MLOps)
6. Benchmarks & Competitions
7. Public Notes / Writing
8. Roadmap & Changelog
---
### Vision & Rules of the game


Vision: Build endâ€‘toâ€‘end ML systems that solve real problems (healthcare, law, finance).
Rules:
One production project per year + 2â€“3 small projects.
1 paper/week: read â†’ reproduce a key ablation â†’ short note.
Publicly track progress (this README), keep code clean, measure value.
Domains Iâ€™m exploring:
ğŸ©º Healthcare (tabular/CV) â€” triage from blood panels, segmentation.
âš–ï¸ Legal NLP / RAG â€” retrieval, reranking, faithfulness metrics.
ğŸ“ˆ RL in Trading â€” riskâ€‘aware baselines, transaction costs, walkâ€‘forward.


---
## Curriculum & Progress
Progress legend: âœ… done â€¢ ğŸ”„ in progress â€¢ â³ planned
### Foundations (0â€“6 months)
â³ fast.ai â€“ Practical Deep Learning for Coders


Repo notes: `01_course_notes/fastai/`


ğŸ”„ DeepLearning.AI â€“ Machine Learning Specialization (Ng)


Repo notes: `01_course_notes/ng-ml-spec/`


â³ DeepLearning.AI â€“ Deep Learning Specialization (Ng)


Repo notes: `01_course_notes/ng-dl-spec/`


### Specializations (6â€“18 months)
â³ Stanford CS231n (CV) â€” convnets, modern architectures


Notes: `01_course_notes/cs231n/`


â³ Stanford CS224n (NLP) â€” transformers, attention, seq2seq


Notes: `01_course_notes/cs224n/`


â³ Hugging Face â€“ LLM Course â€” transformers/datasets/accelerate


Notes: `01_course_notes/hf-llm/`


### MLOps / Production (12â€“24 months)
â³ Full Stack Deep Learning â€” data â†’ train â†’ deploy â†’ monitor


Notes: 01_course_notes/fsdl/


â³ ML in Production (DLAI) â€” pipelines, registries, CI/CD


Notes: 01_course_notes/dlai-ml-prod/


### Math & Stats (anytime)

â³ Linear Algebra refresh (SVD, eigens, norms)


â³ Prob/Stats (Bayes, calibration, uncertainty)


â³ Optimization (GD/Adam, LR schedules, regularization)


---
## Projects (productionâ€‘grade)


---
## Research Practice (Paper Log)


1 paper/week â†’ small reproduction or ablation. Keep it honest and brief.
Log format (`02_papers/`):
`YYYYâ€‘MMâ€‘DD  |  Paper Title  |  Link  |  What I reproduced  |  Key takeaway  |  Next experiment`
Examples:
`2025â€‘10â€‘12 | Attention Is All You Need | link | Reâ€‘ran small Transformer on toy task | Scaling laws intuition | Try RoPE/ALiBi`
`2025â€‘10â€‘05 | BERT | link | MLM fineâ€‘tune on domain corpus | Tokenization matters | Add reranker baseline`


---
## Benchmarks & Competitions


---
## Public Notes / Writing


---
## Roadmap & Changelog


---

### Repository Structure
```Bash
ML-Specialist-Roadmap/
â”œâ”€ 01_course_notes/
â”‚ â”œâ”€ fastai/
â”‚ â”œâ”€ ng-ml-spec/
â”‚ â”œâ”€ ng-dl-spec/
â”‚ â”œâ”€ cs231n/
â”‚ â”œâ”€ cs224n/
â”‚ â””â”€ hf-llm/
â”œâ”€ 02_papers/
â”‚ â””â”€ paper-log.md
â”œâ”€ 03_projects/
â”‚ â”œâ”€ prokect-01/
â”œâ”€ 04_templates/
â”‚ â””â”€ project_template/
â”œâ”€ benchmarks/
â”œâ”€ notes/
â”œâ”€ talks/
â”œâ”€ .github/workflows/ci.yml
â”œâ”€ pyproject.toml
â”œâ”€ requirements.txt or uv.lock
â”œâ”€ Makefile
â””â”€ README.md (this file)
```

